{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8134fdb9-2626-4cdb-aaba-b203ff45d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d7413d91-89a6-4c86-bc6a-4b36451a1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "load_dotenv(override=True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d161c8-4eb5-4abf-8983-039a9b3f3c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI key loaded\n",
      "anthropic key loaded\n",
      "deepseek key loaded\n"
     ]
    }
   ],
   "source": [
    "if open_api_key:\n",
    "    print('OPENAI key loaded')\n",
    "else:\n",
    "    print('OPENAI key not loaded')\n",
    "if anthropic_api_key:\n",
    "    print('anthropic key loaded')\n",
    "else:\n",
    "    print('anthropic key not loaded')\n",
    "if deepseek_api_key:\n",
    "    print('deepseek key loaded')\n",
    "else:\n",
    "    print('deepseek key not loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f2f5b1-21a9-4516-97ab-7de3c8a7d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "deepseek = OpenAI(api_key=deepseek_api_key,base_url=\"https://api.deepseek.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bfb901a-6ecb-4a50-b0e3-9324b39bcc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to keep costs ultra-low? Uncomment these lines:\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "CLAUDE_MODEL = \"claude-3-haiku-20240307\"\n",
    "DEEPSEEK_MODEL = 'deepseek-coder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b5823a6-bd75-48f2-90ae-6f4b016ed478",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = (\n",
    "    \"You are an assistant that adds docstrings to functions and comments to code where necessary. \"\n",
    "    \"Do not modify the code itself ‚Äî only add docstrings and explanatory comments. \"\n",
    "    \"The functionality of the code must remain exactly the same. \"\n",
    "    \"Do not explain your reasoning or what additions you made ‚Äî just add docstrings and comments to the code. \"\n",
    "    \"Return only the modified version of the code, with no extra explanations or comments beyond what was asked.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bdbaa289-c909-40fa-9484-f4574a4067c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(code):\n",
    "    user_prompt = (\n",
    "        \"Add comments to the following code.\\n\"\n",
    "        \"DO NOT change the functionality of the code.\\n\\n\"\n",
    "        f\"{code}\"\n",
    "    )\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5a901e5-f968-4651-8d99-e0bcbee4b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(code):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(code)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fedef6a-4d86-4f0f-a1a2-56487d708693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(code):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages_for(code),\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        result += fragment\n",
    "        yield result.replace('```python\\n','').replace('```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86d0f911-072f-4e8f-9301-1bb725c1966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_deepseek(code):\n",
    "    stream = deepseek.chat.completions.create(\n",
    "        model=DEEPSEEK_MODEL,\n",
    "        messages=messages_for(code),\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        result += fragment\n",
    "        yield result.replace('```python\\n','').replace('```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f24b4805-46ac-4d98-b84d-ef9b8bbb0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(code):\n",
    "    result = claude.messages.stream(\n",
    "        model= CLAUDE_MODEL,\n",
    "        max_tokens=2000,\n",
    "        system=system_message,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt_for(code)}]\n",
    "    )\n",
    "    reply = ''\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield reply.replace('```python\\n','').replace('```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d23a0343-9919-47fd-8537-e73427c1e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_hard = \"\"\"\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26a34011-ecde-422e-b4dd-943ccb9c16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docstring(python, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(python)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(python)\n",
    "    elif model == \"DeepSeek\":\n",
    "        result = stream_deepseek(python)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5acb31cd-80ca-4d7c-8e52-8af3354dcacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_unit_test = (\n",
    "    \"You are an assistant that generates Python unit test code for the given code. \"\n",
    "    \"Do not modify the original code ‚Äî only write test cases that thoroughly cover the functionality. \"\n",
    "    \"Use the standard unittest framework syntax. \"\n",
    "    \"Return only the test code, no explanations or additional text. \"\n",
    "    \"The tests should be clear, concise, and runnable as-is.\"\n",
    ")\n",
    "def user_prompt_unit_test(code: str) -> str:\n",
    "    return (\n",
    "        \"Write Python unit tests for the following code using the unittest module. \"\n",
    "        \"Do not change the original code. Only add test cases to verify its behavior.\\n\\n\"\n",
    "        f\"{code}\"\n",
    "    )\n",
    "def messages_for_test(code):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message_unit_test},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_unit_test(code)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b46d39a-dad7-4718-8c77-5dded1edd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt_test(code):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages_for_test(code),\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        result += fragment\n",
    "        yield result.replace('```python\\n','').replace('```','')\n",
    "##############\n",
    "def stream_deepseek_test(code):\n",
    "    stream = deepseek.chat.completions.create(\n",
    "        model=DEEPSEEK_MODEL,\n",
    "        messages=messages_for_test(code),\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        result += fragment\n",
    "        yield result.replace('```python\\n','').replace('```','')\n",
    "######################\n",
    "def stream_claude_test(code):\n",
    "    result = claude.messages.stream(\n",
    "        model= CLAUDE_MODEL,\n",
    "        max_tokens=2000,\n",
    "        system=system_message_unit_test,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt_unit_test(code)}]\n",
    "    )\n",
    "    reply = ''\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield reply.replace('```python\\n','').replace('```','')\n",
    "#####################\n",
    "def unit_test(python, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt_test(python)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude_test(python)\n",
    "    elif model == \"DeepSeek\":\n",
    "        result = stream_deepseek_test(python)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b44f6f8f-cdb3-40ed-833d-c320a56932e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = \"\"\"def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a6f7c864-3fb4-490d-8fe4-7ec174244263",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_explaio = (\n",
    "    \"You are a helpful assistant that explains Python code in clear, beginner-friendly terms. \"\n",
    "    \"Break down the logic, describe the purpose of functions and classes, and clarify complex parts. \"\n",
    "    \"Use simple language, bullet points, and examples where appropriate. \"\n",
    "    \"Do not modify or rewrite the code. Just explain what it does and how it works.\"\n",
    ")\n",
    "def user_prompt_explaio(code: str) -> str:\n",
    "    return (\n",
    "        \"Explain the following Python code in simple terms. \"\n",
    "        \"Provide an overview of what the code does and explain any functions, loops, or logic used.\\n\\n\"\n",
    "        f\"{code}\"\n",
    "    )\n",
    "def messages_for_explaio(code):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message_explaio},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_explaio(code)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "92f8b50e-6722-494b-9b83-8f770a23b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt_explain(code):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages_for_explaio(code),\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        result += fragment\n",
    "        yield result.replace('```python\\n','').replace('```','')\n",
    "##############\n",
    "def stream_deepseek_explain(code):\n",
    "    stream = deepseek.chat.completions.create(\n",
    "        model=DEEPSEEK_MODEL,\n",
    "        messages=messages_for_explaio(code),\n",
    "        stream=True\n",
    "    )\n",
    "    result = ''\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        result += fragment\n",
    "        yield result.replace('```python\\n','').replace('```','')\n",
    "######################\n",
    "def stream_claude_explain(code):\n",
    "    result = claude.messages.stream(\n",
    "        model= CLAUDE_MODEL,\n",
    "        max_tokens=2000,\n",
    "        system=system_message_explaio,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt_explaio(code)}]\n",
    "    )\n",
    "    reply = ''\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield reply.replace('```python\\n','').replace('```','')\n",
    "#####################\n",
    "def explain_code(code, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt_explain(code)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude_explain(code)\n",
    "    elif model == \"DeepSeek\":\n",
    "        result = stream_deepseek_explain(code)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "416ea1c8-5378-463b-adcb-a61c8889a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_example = \"\"\"\n",
    "class ExpressionError(Exception):\n",
    "    pass\n",
    "\n",
    "class ExpressionEvaluator:\n",
    "    def __init__(self, expression):\n",
    "        self.expression = expression.replace(\" \", \"\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        try:\n",
    "            return self._evaluate_expression(self.expression)\n",
    "        except ZeroDivisionError:\n",
    "            raise ExpressionError(\"Division by zero is not allowed.\")\n",
    "        except Exception as e:\n",
    "            raise ExpressionError(f\"Invalid expression: {e}\")\n",
    "\n",
    "    def _evaluate_expression(self, expr):\n",
    "        if expr.isdigit():\n",
    "            return int(expr)\n",
    "\n",
    "        for op in ['+', '-', '*', '/']:\n",
    "            depth = 0\n",
    "            for i in range(len(expr) - 1, -1, -1):\n",
    "                if expr[i] == ')':\n",
    "                    depth += 1\n",
    "                elif expr[i] == '(':\n",
    "                    depth -= 1\n",
    "                elif depth == 0 and expr[i] == op:\n",
    "                    left = self._evaluate_expression(expr[:i])\n",
    "                    right = self._evaluate_expression(expr[i + 1:])\n",
    "                    return self._apply_operator(op, left, right)\n",
    "\n",
    "        if expr[0] == '(' and expr[-1] == ')':\n",
    "            return self._evaluate_expression(expr[1:-1])\n",
    "\n",
    "        raise ExpressionError(\"Malformed expression\")\n",
    "\n",
    "    def _apply_operator(self, op, a, b):\n",
    "        if op == '+':\n",
    "            return a + b\n",
    "        elif op == '-':\n",
    "            return a - b\n",
    "        elif op == '*':\n",
    "            return a * b\n",
    "        elif op == '/':\n",
    "            if b == 0:\n",
    "                raise ZeroDivisionError()\n",
    "            return a / b\n",
    "        else:\n",
    "            raise ExpressionError(f\"Unsupported operator: {op}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dccfa41f-9d4c-479c-be7b-cc40e3304fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OPTIONS = [\"GPT\", \"Claude\", \"DeepSeek\"]\n",
    "with gr.Blocks(title=\"Code Assistant\", theme=gr.themes.Soft()) as ui:\n",
    "    with gr.Tabs():\n",
    "        # Docstring Adder Tab\n",
    "        with gr.Tab(\"DocoBot\"):\n",
    "            gr.Markdown(\"### üìù DocuBot: Auto-Generate Docstrings & Comments\")\n",
    "            with gr.Row():\n",
    "                docu_code_input = gr.Code(\n",
    "                    label=\"Input Code\",\n",
    "                    language=\"python\",\n",
    "                    lines=20,\n",
    "                    value=python_hard                )\n",
    "                docu_output = gr.Code(\n",
    "                    label=\"Output Code with Docstrings\",\n",
    "                    language=\"python\",\n",
    "                    lines=20,\n",
    "                    interactive=False\n",
    "                )\n",
    "            with gr.Row():\n",
    "                docu_model_select = gr.Dropdown(\n",
    "                    MODEL_OPTIONS,\n",
    "                    value=\"DeepSeek\",\n",
    "                    label=\"Select Model\"\n",
    "                )\n",
    "            with gr.Row():\n",
    "                docu_convert_btn = gr.Button(\"Add Docstrings\")\n",
    "                docu_clear_btn = gr.Button(\"Clear\")\n",
    "\n",
    "            # Call docstring function on button click\n",
    "            docu_convert_btn.click(\n",
    "                fn=docstring,\n",
    "                inputs=[docu_code_input, docu_model_select],\n",
    "                outputs=[docu_output]\n",
    "            )\n",
    "            # Clear inputs and outputs\n",
    "            docu_clear_btn.click(\n",
    "                fn=lambda: (\"\", \"\"),\n",
    "                inputs=[],\n",
    "                outputs=[docu_code_input, docu_output]\n",
    "            )\n",
    "\n",
    "        # Unit Test Case Adder Tab\n",
    "        with gr.Tab(\"TestoBot\"):\n",
    "            gr.Markdown(\"### üß™ TestIT: Instantly Add Unit Tests to Your Code\")\n",
    "\n",
    "            with gr.Row():\n",
    "                test_code_input = gr.Code(\n",
    "                    label=\"Input Code\",\n",
    "                    language=\"python\",\n",
    "                    lines=20,\n",
    "                    value=test_case                )\n",
    "                test_output = gr.Code(\n",
    "                    label=\"Output Code with Unit Tests\",\n",
    "                    language=\"python\",\n",
    "                    lines=20,\n",
    "                    interactive=False\n",
    "                )\n",
    "            with gr.Row():\n",
    "                test_model_select = gr.Dropdown(\n",
    "                    MODEL_OPTIONS,\n",
    "                    value=\"DeepSeek\",\n",
    "                    label=\"Select Model\"\n",
    "                )\n",
    "            with gr.Row():\n",
    "                test_convert_btn = gr.Button(\"Add Unit Tests\")\n",
    "                test_clear_btn = gr.Button(\"Clear\")\n",
    "\n",
    "            # Call unit_test function on button click\n",
    "            test_convert_btn.click(\n",
    "                fn=unit_test,\n",
    "                inputs=[test_code_input, test_model_select],\n",
    "                outputs=[test_output]\n",
    "            )\n",
    "            # Clear inputs and outputs\n",
    "            test_clear_btn.click(\n",
    "                fn=lambda: (\"\", \"\"),\n",
    "                inputs=[],\n",
    "                outputs=[test_code_input, test_output]\n",
    "            )\n",
    "        with gr.Tab(\"üß† ExplaioBot\"):\n",
    "            gr.Markdown(\"## üß† Understand Your Code\")\n",
    "        \n",
    "            with gr.Row():\n",
    "                code = gr.Code(label=\"üßæ Your Code\", lines=20,language='python', value=python_example)\n",
    "                output = gr.Textbox(label=\"üß† Explanation\", lines=35)\n",
    "        \n",
    "            with gr.Row():\n",
    "                model = gr.Dropdown([\"GPT\", \"Claude\", \"DeepSeek\"], value=\"DeepSeek\", label=\"Select Model\")\n",
    "        \n",
    "            with gr.Row():\n",
    "                explain_btn = gr.Button(\"üîç Explain Code\")\n",
    "        \n",
    "            explain_btn.click(fn=explain_code, inputs=[code, model], outputs=[output])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "73b7596f-07fb-44a5-a2a5-9e5b113871c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7894\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7894/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch(inbrowser=True)\n",
    "#ui.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff0391-bf3a-4141-958f-2ee2dc3581b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
